{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# E-Commerce Customer Review Prediction Model : Shubham Agrawal"
      ],
      "metadata": {
        "id": "o_4JJIcidbjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Required Libraries"
      ],
      "metadata": {
        "id": "ggfnWpasKc-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVF5xMZPKNOv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Each File"
      ],
      "metadata": {
        "id": "jL0EvGwAKcK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('olist_customers_dataset.csv')\n",
        "geolocation = pd.read_csv('olist_geolocation_dataset.csv')\n",
        "order_items = pd.read_csv('olist_order_items_dataset.csv')\n",
        "order_payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
        "order_reviews = pd.read_csv('olist_order_reviews_dataset.csv')\n",
        "orders = pd.read_csv('olist_orders_dataset.csv')\n",
        "products = pd.read_csv('olist_products_dataset.csv')\n",
        "sellers = pd.read_csv('olist_sellers_dataset.csv')\n",
        "product_category_translation = pd.read_csv('product_category_name_translation.csv')"
      ],
      "metadata": {
        "id": "ARURDCVyKZUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the Datasets"
      ],
      "metadata": {
        "id": "2hKMJk0OEmIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1. Customers\n",
        "Dataset*"
      ],
      "metadata": {
        "id": "7icem8BMKbwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(customers.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "customers = customers.drop_duplicates()\n",
        "\n",
        "# Step 3: Standardize categorical data\n",
        "customers['customer_state'] = customers['customer_state'].str.upper()  # Convert state codes to uppercase\n",
        "customers['customer_city'] = customers['customer_city'].str.lower()    # Convert city names to lowercase\n",
        "string_columns = customers.select_dtypes(include=['object']).columns\n",
        "customers[string_columns] = customers[string_columns].apply(lambda x: x.str.strip())  # Strip whitespace\n",
        "\n",
        "# Step 4: Validate and drop invalid geographic states\n",
        "valid_states = ['AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MT', 'MS', 'MG', 'PA', 'PB', 'PR',\n",
        "                'PE', 'PI', 'RJ', 'RN', 'RS', 'RO', 'RR', 'SC', 'SP', 'SE', 'TO']\n",
        "customers = customers[customers['customer_state'].isin(valid_states)]\n",
        "\n",
        "# Step 5: Check for Missing Values\n",
        "print(\"\\nChecking for missing values...\")\n",
        "missing_values = customers.isnull().sum()\n",
        "print(missing_values)\n",
        "#There are no missing values\n"
      ],
      "metadata": {
        "id": "tqrCheK9Lm0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2. Geolocation Dataset*"
      ],
      "metadata": {
        "id": "duEUut20MxR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(geolocation.info())\n",
        "\n",
        "# Step 2: Remove duplicates\n",
        "geolocation = geolocation.drop_duplicates()\n",
        "\n",
        "# Step 3: Standardize categorical columns\n",
        "geolocation['geolocation_state'] = geolocation['geolocation_state'].str.upper()\n",
        "geolocation['geolocation_city'] = geolocation['geolocation_city'].str.lower()\n",
        "string_columns = geolocation.select_dtypes(include=['object']).columns\n",
        "geolocation[string_columns] = geolocation[string_columns].apply(lambda x: x.str.strip())\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "missing_values = geolocation.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "\n",
        "# Step 5: Validate and remove invalid latitude/longitude values\n",
        "geolocation = geolocation[\n",
        "    (geolocation['geolocation_lat'].between(-90, 90)) &\n",
        "    (geolocation['geolocation_lng'].between(-180, 180))\n",
        "]"
      ],
      "metadata": {
        "id": "hU2oa9rpNir6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*3. Order items Dataset*"
      ],
      "metadata": {
        "id": "5biNLPN1Nw5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(order_items.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "order_items = order_items.drop_duplicates()\n",
        "\n",
        "# Step 3: Handle invalid or missing values\n",
        "# Step 3.1 Convert 'shipping_limit_date' to datetime format\n",
        "if 'shipping_limit_date' in order_items.columns:\n",
        "    order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'])\n",
        "\n",
        "# Step 3.2: Check for Missing Values\n",
        "print(\"\\nChecking for missing values...\")\n",
        "missing_values = order_items.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Step 3.4 Ensure 'price' and 'freight_value' are valid\n",
        "order_items = order_items[(order_items['price'] > 0) & (order_items['freight_value'] >= 0)]\n",
        "\n",
        "# Step 4: Standardize string columns\n",
        "string_columns = order_items.select_dtypes(include=['object']).columns\n",
        "order_items[string_columns] = order_items[string_columns].apply(lambda x: x.str.strip())\n"
      ],
      "metadata": {
        "id": "qDIPDfQSN7fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*4. Order Payments Dataset*"
      ],
      "metadata": {
        "id": "gaitMf25O_yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(order_payments.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "order_payments = order_payments.drop_duplicates()\n",
        "\n",
        "# Step 3: Handle invalid or missing values\n",
        "missing_values = order_payments.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Ensure 'payment_value' is positive or at least 0\n",
        "order_payments = order_payments[order_payments['payment_value'] >= 0]\n",
        "\n",
        "# Ensure 'payment_installments' is greater than 0\n",
        "order_payments = order_payments[order_payments['payment_installments'] > 0]\n",
        "\n",
        "# Remove rows where 'payment_type' is 'not_defined'\n",
        "order_payments = order_payments[order_payments['payment_type'] != 'not_defined']\n",
        "\n",
        "# Step 4: Standardize string columns\n",
        "# Convert 'payment_type' to lowercase\n",
        "order_payments['payment_type'] = order_payments['payment_type'].str.lower()\n",
        "\n",
        "# Strip whitespace from string columns\n",
        "string_columns = order_payments.select_dtypes(include=['object']).columns\n",
        "order_payments[string_columns] = order_payments[string_columns].apply(lambda x: x.str.strip())\n",
        "\n",
        "# Step 5: Check for continuity of 'payment_sequential'\n",
        "def is_sequential(seq):\n",
        "    # Check if the sequence starts from 1 and is continuous\n",
        "    return sorted(seq) == list(range(1, len(seq) + 1))\n",
        "\n",
        "# Identify valid order IDs where 'payment_sequential' is continuous\n",
        "valid_order_ids = (\n",
        "    order_payments.groupby('order_id')['payment_sequential']\n",
        "    .apply(is_sequential)\n",
        "    .reset_index()\n",
        "    .rename(columns={'payment_sequential': 'is_sequential'})\n",
        ")\n",
        "\n",
        "# Merge back with the original dataset to filter only valid rows\n",
        "order_payments = order_payments.merge(valid_order_ids, on='order_id')\n",
        "order_payments = order_payments[order_payments['is_sequential']]\n",
        "order_payments = order_payments.drop(columns=['is_sequential'])\n",
        "\n",
        "# Step 6: Aggregate data to ensure one row per 'order_id'\n",
        "aggregated_payments = order_payments.groupby('order_id').agg({\n",
        "    'payment_sequential': 'max',  # Highest payment sequential\n",
        "    'payment_type': lambda x: ', '.join(sorted(x.unique())),  # Unique payment types, comma-separated\n",
        "    'payment_installments': 'max',  # Highest installments\n",
        "    'payment_value': 'sum'  # Total payment value\n",
        "}).reset_index()\n",
        "\n",
        "# Display the aggregated DataFrame\n",
        "print(aggregated_payments.head())\n",
        "\n",
        "# Save the aggregated DataFrame\n",
        "aggregated_payments.to_csv('aggregated_payments.csv', index=False)\n",
        "print(\"Aggregated data saved to 'aggregated_payments.csv'\")\n"
      ],
      "metadata": {
        "id": "al98LcuPnTIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*5. Order Reviews Dataset*"
      ],
      "metadata": {
        "id": "ZK23SiEVPt-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(order_reviews.info())\n",
        "\n",
        "# Step 2.1: Check Missing Values\n",
        "missing_values = order_reviews.isnull().sum()\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Step 2.2: Check Missing Values Percentage\n",
        "missing_percentage = (order_reviews.isnull().mean() * 100).round(2)  # Calculate percentage of missing values\n",
        "print(missing_percentage)\n",
        "\n",
        "# Step 3: Remove unnecessary columns with too high % of missing values\n",
        "order_reviews = order_reviews.drop(columns=['review_comment_title', 'review_comment_message'], errors='ignore')\n",
        "\n",
        "# Count duplicates in 'order_id'\n",
        "duplicate_count = order_reviews.duplicated(subset='order_id').sum()\n",
        "print(f\"\\nNumber of duplicate 'order_id' entries: {duplicate_count}\")\n",
        "\n",
        "# Step 4: Keep only the final row of reviews for each order\n",
        "order_reviews = order_reviews.sort_values(by='review_answer_timestamp').drop_duplicates(subset='order_id', keep='last')\n",
        "\n",
        "# Step 5: Handle missing values\n",
        "# Drop rows with missing values in critical columns\n",
        "critical_columns = ['review_id', 'order_id', 'review_score']\n",
        "order_reviews = order_reviews.dropna(subset=critical_columns)\n",
        "\n",
        "# Step 6: Convert date fields to datetime\n",
        "date_columns = ['review_creation_date', 'review_answer_timestamp']\n",
        "for col in date_columns:\n",
        "    order_reviews[col] = pd.to_datetime(order_reviews[col], dayfirst=True)\n",
        "\n",
        "# Step 7: Standardize string columns\n",
        "string_columns = order_reviews.select_dtypes(include=['object']).columns\n",
        "order_reviews[string_columns] = order_reviews[string_columns].apply(lambda x: x.str.strip())\n"
      ],
      "metadata": {
        "id": "BwK7ZfVlPx6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*6. Orders Dataset*"
      ],
      "metadata": {
        "id": "sZr5HkF9QaYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(orders.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "orders = orders.drop_duplicates()\n",
        "\n",
        "# Step 3: Missing values\n",
        "missing_values = orders.isnull().sum()\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "# Drop rows with missing values in critical columns\n",
        "critical_columns = ['order_id', 'customer_id', 'order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
        "orders = orders.dropna(subset=critical_columns)\n",
        "\n",
        "# Step 6: Convert date fields to datetime\n",
        "date_columns = [\n",
        "    'order_purchase_timestamp',\n",
        "    'order_approved_at',\n",
        "    'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date',\n",
        "    'order_estimated_delivery_date'\n",
        "]\n",
        "for col in date_columns:\n",
        "    orders[col] = pd.to_datetime(orders[col])\n",
        "\n",
        "# Step7: Validate and clean date relationships\n",
        "# Ensure carrier delivery is after purchase,customer delivery is after carrier delivery\n",
        "orders = orders[\n",
        "   (orders['order_delivered_carrier_date'] >= orders['order_purchase_timestamp'])|\n",
        "   (orders['order_approved_at'] >= orders['order_purchase_timestamp'])|\n",
        "   (orders['order_delivered_customer_date'] >= orders['order_delivered_carrier_date'])\n",
        "]\n"
      ],
      "metadata": {
        "id": "ahGUR8R4QesS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*7. Products Dataset*"
      ],
      "metadata": {
        "id": "kqJBwo2jRtuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(products.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "products = products.drop_duplicates()\n",
        "\n",
        "# Step 3: Standardize and clean categorical columns\n",
        "if 'product_category_name' in products.columns:\n",
        "    products['product_category_name'] = products['product_category_name'].str.strip().str.lower()\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "missing_values = products.isnull().sum()\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "critical_columns = ['product_id', 'product_category_name']\n",
        "products = products.dropna(subset=critical_columns)\n",
        "\n",
        "# Step 5: Validate and clean numeric fields\n",
        "# Ensure product weight, length, height, and width are positive\n",
        "numeric_columns = [\n",
        "    'product_weight_g',\n",
        "    'product_length_cm',\n",
        "    'product_height_cm',\n",
        "    'product_width_cm'\n",
        "]\n",
        "for col in numeric_columns:\n",
        "    if col in products.columns:\n",
        "        products = products[products[col] > 0]\n"
      ],
      "metadata": {
        "id": "4D-FZf1KSTYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*8. Sellers Dataset*"
      ],
      "metadata": {
        "id": "G7iD_uOvS3yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(sellers.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "sellers = sellers.drop_duplicates()\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "missing_values = sellers.isnull().sum()\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Step 4: Standardize categorical columns\n",
        "# Convert state codes to uppercase and city names to lowercase\n",
        "sellers['seller_city'] = sellers['seller_city'].str.strip().str.lower()\n",
        "sellers['seller_state'] = sellers['seller_state'].str.strip().str.upper()\n"
      ],
      "metadata": {
        "id": "2dYfNuXeS3i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*9. Translation Dataset*"
      ],
      "metadata": {
        "id": "0LjMMGuNTBAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Overview of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(product_category_translation.info())\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "product_category_translation = product_category_translation.drop_duplicates()\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "missing_values = product_category_translation.isnull().sum()\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Step 4: Standardize categorical columns\n",
        "# Strip whitespace and convert to lowercase for consistency\n",
        "product_category_translation['product_category_name'] = product_category_translation['product_category_name'].str.strip().str.lower()\n",
        "product_category_translation['product_category_name_english'] = product_category_translation['product_category_name_english'].str.strip().str.lower()\n"
      ],
      "metadata": {
        "id": "Fa44uNmWTD4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merging the Datasets"
      ],
      "metadata": {
        "id": "hXlcr13vZtxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Merge customers with orders\n",
        "customers_orders = pd.merge(customers, orders, on='customer_id', how='inner')\n",
        "\n",
        "# Step 2: Merge customers_orders with order_reviews\n",
        "customers_orders_reviews = pd.merge(customers_orders, order_reviews, on='order_id', how='inner')\n",
        "\n",
        "# Step 3: Merge customers_orders_reviews with aggregated_payments\n",
        "customers_orders_reviews_payments = pd.merge(customers_orders_reviews, aggregated_payments, on='order_id', how='inner')\n",
        "\n",
        "# Step 4: Merge customers_orders_reviews_payments with order_items\n",
        "customers_orders_items = pd.merge(customers_orders_reviews_payments, order_items, on='order_id', how='inner')\n",
        "\n",
        "# Step 5: Merge customers_orders_items with products\n",
        "customers_orders_items_products = pd.merge(customers_orders_items, products, on='product_id', how='inner')\n",
        "\n",
        "# Step 6: Merge customers_orders_items_products with sellers\n",
        "customers_orders_items_products_sellers = pd.merge(customers_orders_items_products, sellers, on='seller_id', how='inner')\n",
        "\n",
        "# Step 7: Merge customers_orders_items_products_sellers with translation\n",
        "final_merged_data = pd.merge(\n",
        "    customers_orders_items_products_sellers,\n",
        "    product_category_translation,\n",
        "    left_on='product_category_name',\n",
        "    right_on='product_category_name',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Final merged dataset\n",
        "final_merged_data.to_csv('final_merged_data.csv', index=False)\n",
        "print(\"Final merged dataset saved to 'final_merged_data.csv'\")"
      ],
      "metadata": {
        "id": "ZgaUxTdSZvd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning the Merged Dataset"
      ],
      "metadata": {
        "id": "bh7H266NaUpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 1: Checking the missing values\n",
        "\n"
      ],
      "metadata": {
        "id": "Z_2SiSFPcP3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'final_merged_data.csv'\n",
        "final_data = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate missing values and their percentage\n",
        "missing_data = final_data.isnull().sum().reset_index()\n",
        "missing_data.columns = ['Column', 'Missing_Values']\n",
        "missing_data['Percentage_Missing'] = (missing_data['Missing_Values'] / len(final_data)) * 100\n",
        "\n",
        "# Print missing values and percentages\n",
        "print(\"Missing Values and Percentages per Column:\")\n",
        "print(missing_data)"
      ],
      "metadata": {
        "id": "0Hz4rW3xaX8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Fill in the Missing values for Category names in English"
      ],
      "metadata": {
        "id": "tFcJ5GL4eKj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify rows with missing translations\n",
        "missing_translations = final_data[final_data['product_category_name_english'].isnull()]\n",
        "print(missing_translations[['product_category_name', 'product_category_name_english']])"
      ],
      "metadata": {
        "id": "roYxS0Kgjwz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation_dict = {\n",
        "    'portateis_cozinha_e_preparadores_de_alimentos': 'portable kitchen and food preparation devices',\n",
        "    'pc_gamer': 'gaming pc'\n",
        "}\n",
        "\n",
        "# Replace missing translations using the dictionary\n",
        "final_data['product_category_name_english'] = final_data['product_category_name_english'].fillna(\n",
        "    final_data['product_category_name'].map(translation_dict)\n",
        ")\n",
        "\n",
        "# Verify if all missing values are replaced\n",
        "print(final_data['product_category_name_english'].isnull().sum())"
      ],
      "metadata": {
        "id": "C1kkWtn8424E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Identifying and Removing Inconsistent Date Entries from the Dataset"
      ],
      "metadata": {
        "id": "gWU6jC_6qns9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify invalid rows\n",
        "invalid_rows_condition = (\n",
        "    (final_data['review_creation_date'] < final_data['order_delivered_customer_date']) |\n",
        "    (final_data['review_creation_date'] < final_data['order_purchase_timestamp'])\n",
        ")\n",
        "\n",
        "# Count invalid rows\n",
        "invalid_rows_count = final_data[invalid_rows_condition].shape[0]\n",
        "print(f\"Number of invalid rows (review date earlier than purchase or delivery date): {invalid_rows_count}\")\n",
        "\n",
        "# Remove invalid rows\n",
        "cleaned_data = final_data[~invalid_rows_condition]\n",
        "\n",
        "# Save cleaned data\n",
        "cleaned_data.to_csv('cleaned_merged_data.csv', index=False)"
      ],
      "metadata": {
        "id": "ShAr7U975WHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows in the cleaned merged dataset\n",
        "cleaned_merged_data = pd.read_csv('cleaned_merged_data.csv')\n",
        "num_rows = len(cleaned_merged_data)\n",
        "print(f\"The cleaned merged dataset has {num_rows} rows.\")"
      ],
      "metadata": {
        "id": "auJFe-fE7ZM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Removing Duplicates"
      ],
      "metadata": {
        "id": "Oa9f-Wnk9COQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Duplicates : Remove orders with multiple items\n",
        "# Group by order ID and count the number of items in each order\n",
        "order_counts = cleaned_merged_data.groupby('order_id')['order_item_id'].count()\n",
        "\n",
        "# Identify orders with only one item\n",
        "single_item_orders = order_counts[order_counts == 1].index\n",
        "\n",
        "# Filter the DataFrame to keep only orders with a single item\n",
        "cleaned_merged_data_single_item = cleaned_merged_data[cleaned_merged_data['order_id'].isin(single_item_orders)]\n",
        "\n",
        "num_rows_clean = len(cleaned_merged_data_single_item)\n",
        "print(f\"The further cleaned merged dataset has {num_rows_clean} rows.\")\n",
        "\n",
        "# Save the cleaned dataset without duplicates (orders with multiple items)\n",
        "cleaned_merged_data_single_item.to_csv('cleaned_merged_data_single_item.csv', index=False)\n",
        "print(\"Cleaned merged dataset (single item orders) saved to 'cleaned_merged_data_single_item.csv'\")"
      ],
      "metadata": {
        "id": "I9p5eJytrkK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Filtering out Delivered Orders"
      ],
      "metadata": {
        "id": "HBWS4pAWGRAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Order Status : Remove orders that are not Delivered\n",
        "\n",
        "# Load the dataset into Orders\n",
        "orderStatus = pd.read_csv('cleaned_merged_data_single_item.csv')\n",
        "\n",
        "# Remove rows where 'order_status' is not 'delivered'\n",
        "orderStatus = orderStatus[orderStatus['order_status'].str.strip().str.lower() == 'delivered']\n",
        "\n",
        "# Save the filtered dataset\n",
        "filtered_orders_file_path = 'orders_only_delivered_single_item.csv'\n",
        "orderStatus.to_csv(filtered_orders_file_path, index=False)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Filtered dataset saved with {orderStatus.shape[0]} rows where 'order_status' is 'delivered'.\")"
      ],
      "metadata": {
        "id": "mWdc4trEqstV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Add columns for new features"
      ],
      "metadata": {
        "id": "5kFQxSOxGfam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#New column : Delivery Time = Delivery Customer Data - Purchase Timestamp\n",
        "#New column : Delivery Delay = Delivery Customer Data - Estimated Delivery Date\n",
        "#New Column : Review to Delivery Time = Review Creation Date - Delivered Date\n",
        "#New column : Freight Price Ratio = Freight value / price"
      ],
      "metadata": {
        "id": "EaPNHlVysGuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('orders_only_delivered_single_item.csv')\n",
        "\n",
        "# Convert relevant columns to datetime for calculations\n",
        "data['order_purchase_timestamp'] = pd.to_datetime(data['order_purchase_timestamp'])\n",
        "data['order_delivered_customer_date'] = pd.to_datetime(data['order_delivered_customer_date'])\n",
        "data['order_estimated_delivery_date'] = pd.to_datetime(data['order_estimated_delivery_date'])\n",
        "data['review_creation_date'] = data['review_creation_date'].apply(lambda x: x + ' 00:00:00' if len(x) == 10 else x)\n",
        "data['review_creation_date'] = pd.to_datetime(data['review_creation_date'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# New column: Delivery Time = Delivered Customer Date - Purchase Timestamp\n",
        "data['delivery_time'] = (data['order_delivered_customer_date'] - data['order_purchase_timestamp']).dt.days\n",
        "\n",
        "# New column: Delivery Customer Date - Estimated Delivery Date\n",
        "data['delivery_delay'] = (data['order_delivered_customer_date'] - data['order_estimated_delivery_date']).dt.days\n",
        "\n",
        "# New column: Review Creation Date - Delivered Date\n",
        "data['review_to_delivery_time'] = (data['review_creation_date'] - data['order_delivered_customer_date']).dt.days\n",
        "\n",
        "# New column: Ratio of Freight Value to Price\n",
        "data['freight_price_ratio'] = data['freight_value'] / data['price']\n",
        "\n",
        "# Save the updated dataset\n",
        "output_file_path = 'orders_with_new_columns.csv'\n",
        "data.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Dataset updated with new columns and saved to {output_file_path}.\")"
      ],
      "metadata": {
        "id": "6_rgFMZI_BL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Outlier Analysis"
      ],
      "metadata": {
        "id": "__z1Ju5B9Y6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('orders_with_new_columns.csv')\n",
        "\n",
        "# Select numerical features specific to the provided dataset\n",
        "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Set up the figure size\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Plot histograms for each numerical feature\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    plt.subplot((len(numerical_features) + 2) // 3, 3, i + 1)  # Create grid of subplots\n",
        "    sns.histplot(data[feature], kde=True, color='skyblue', bins=30)\n",
        "    plt.title(f'Histogram of {feature}', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zo3aBE0bGc0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "id": "5Lo1533vrmrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "Zcd9tUBZnAzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After cleaning the datasets, moving onto comparing different variables to review scores to understand their impact through visualisation and statistical analysis."
      ],
      "metadata": {
        "id": "HGRyLtQUkvJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numerical features\n",
        "numerical_features = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numerical_features.corr()\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar_kws={'label': 'Correlation Coefficient'})\n",
        "plt.title('Correlation Matrix for Numerical Features', fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iLl51o0cJ6Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1. Customer State*"
      ],
      "metadata": {
        "id": "Z-qNEmJ4rVj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for review scores by customer state\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.countplot(data=data, x='customer_state', hue='review_score', palette='Set2')\n",
        "plt.title('Review Score Distribution Across Customer States', fontsize=16)\n",
        "plt.xlabel('Customer State', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title='Review Score', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "O9hulNqFxmkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average review score for each customer state\n",
        "state_avg_reviews = data.groupby('customer_state')['review_score'].mean().reset_index()\n",
        "\n",
        "# Calculate the median of average review scores by state\n",
        "median_state_score = state_avg_reviews['review_score'].median()\n",
        "\n",
        "# Identify states in each group\n",
        "high_performing_states = state_avg_reviews[state_avg_reviews['review_score'] >= median_state_score]['customer_state']\n",
        "low_performing_states = state_avg_reviews[state_avg_reviews['review_score'] < median_state_score]['customer_state']\n",
        "\n",
        "# Filter data for the two groups\n",
        "group_high = data[data['customer_state'].isin(high_performing_states)]['review_score']\n",
        "group_low = data[data['customer_state'].isin(low_performing_states)]['review_score']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(group_high, group_low, equal_var=False)\n",
        "\n",
        "# Print results\n",
        "print(\"T-Test: Impact of Customer State on Review Scores\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between high-performing and low-performing states is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between high-performing and low-performing states is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "GM2JfmNIwoef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2. Payment Type*"
      ],
      "metadata": {
        "id": "Fu5hGumxrfcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for review scores by payment type\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=data, x='payment_type', hue='review_score', palette='Set2')\n",
        "plt.title('Review Score Distribution by Payment Type', fontsize=16)\n",
        "plt.xlabel('Payment Type', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title='Review Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mg1bCkbEz9O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter Data into Two Groups\n",
        "credit_card_reviews = data[data['payment_type'] == 'credit_card']['review_score']\n",
        "other_payment_reviews = data[data['payment_type'] != 'credit_card']['review_score']\n",
        "\n",
        "# Step 2: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(credit_card_reviews, other_payment_reviews, equal_var=False)\n",
        "\n",
        "# Step 3: Print Results\n",
        "print(\"T-Test: Credit Card vs All Other Payment Methods\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between Credit Card and All Other Payment Methods is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between Credit Card and All Other Payment Methods is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "KUAdhUfn0vv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*3. Payment Installments*"
      ],
      "metadata": {
        "id": "rBxFw2Burshm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot for review scores by payment installments\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(data=data, x='payment_installments', y='review_score', color='purple', alpha=0.6)\n",
        "plt.title('Scatter Plot: Payment Installments vs Review Score', fontsize=16)\n",
        "plt.xlabel('Payment Installments', fontsize=12)\n",
        "plt.ylabel('Review Score', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pi1E9Iw9457X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate the median of payment installments\n",
        "median_installments = data['payment_installments'].median()\n",
        "\n",
        "# Step 2: Divide the data into two groups\n",
        "low_installments = data[data['payment_installments'] < median_installments]['review_score']\n",
        "high_installments = data[data['payment_installments'] >= median_installments]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(low_installments, high_installments, equal_var=False)\n",
        "\n",
        "# Step 4: Print Results\n",
        "print(\"T-Test: Low vs High Payment Installments\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between low and high payment installments is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between low and high payment installments is not statistically significant.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "muktBlFe5C-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*4. Price*"
      ],
      "metadata": {
        "id": "35TeyGSqrcq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for review scores by Prices\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=data, x=pd.cut(data['price'], bins=5), y='review_score', palette='Set2')\n",
        "plt.title('Box Plot: Price (Binned) vs Review Score', fontsize=16)\n",
        "plt.xlabel('Price (Binned)', fontsize=12)\n",
        "plt.ylabel('Review Score', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6MeqWuK7x36j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate Median Price\n",
        "median_price = data['price'].median()\n",
        "\n",
        "# Step 2: Divide Data into Low and High Price Groups\n",
        "low_price_group = data[data['price'] < median_price]['review_score']\n",
        "high_price_group = data[data['price'] >= median_price]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(low_price_group, high_price_group, equal_var=False)\n",
        "\n",
        "# Step 4: Print Results\n",
        "print(\"T-Test: Low vs High Price Groups\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between Low and High price groups is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between Low and High price groups is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "TksAu5i9z-de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*5. Freight Value*"
      ],
      "metadata": {
        "id": "AIjB4rCPYP8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bins for freight value to group similar ranges\n",
        "data['freight_value_bins'] = pd.cut(data['freight_value'], bins=10)\n",
        "\n",
        "# Box plot of review scores across freight value ranges\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(data=data, x='freight_value_bins', y='review_score', palette='Set2')\n",
        "plt.title('Review Score Distribution Across Freight Value Ranges', fontsize=16)\n",
        "plt.xlabel('Freight Value Range', fontsize=12)\n",
        "plt.ylabel('Review Score', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oasnJiTweAF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into two groups based on review scores\n",
        "bad_reviews = data[data['review_score'] <= 3]['freight_value']\n",
        "good_reviews = data[data['review_score'] > 3]['freight_value']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(bad_reviews, good_reviews, equal_var=False)  # Use Welch's t-test (unequal variances)\n",
        "\n",
        "# Display results\n",
        "print(\"T-Test Results: Freight Value and Review Scores\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in freight value between the two groups is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in freight value between the two groups is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "VDhNJvssep2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*6. Product Category*"
      ],
      "metadata": {
        "id": "P1uM2n-DYQWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean review scores for each category\n",
        "avg_review_scores = data.groupby('product_category_name_english')['review_score'].mean()\n",
        "\n",
        "# Sort the average review scores\n",
        "avg_review_scores_sorted = avg_review_scores.sort_values()\n",
        "\n",
        "# Select the top 10 and lowest 10 categories\n",
        "lowest_10_categories = avg_review_scores_sorted.head(10)\n",
        "top_10_categories = avg_review_scores_sorted.tail(10)\n",
        "\n",
        "# Combine the top and lowest categories into one DataFrame\n",
        "top_and_lowest = pd.concat([lowest_10_categories, top_10_categories])\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(\n",
        "    x=top_and_lowest.index,\n",
        "    y=top_and_lowest.values,\n",
        "    palette='coolwarm'\n",
        ")\n",
        "plt.title('Top 10 and Lowest 10 Product Categories by Average Review Score', fontsize=16)\n",
        "plt.xlabel('Product Category', fontsize=12)\n",
        "plt.ylabel('Average Review Score', fontsize=12)\n",
        "plt.xticks(rotation=90, ha='right')  # Rotate category names for readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_HVLrfrgfB6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing two random categories to test for significance\n",
        "\n",
        "# Step 1: Define the two categories to compare\n",
        "category_1 = 'sports_leisure'\n",
        "category_2 = 'furniture_decor'\n",
        "\n",
        "# Step 2: Filter the data for the two selected categories\n",
        "category_1_scores = data[data['product_category_name_english'] == category_1]['review_score']\n",
        "category_2_scores = data[data['product_category_name_english'] == category_2]['review_score']\n",
        "\n",
        "# Step 3: Perform t-test\n",
        "t_stat, p_value = ttest_ind(category_1_scores, category_2_scores, equal_var=False)  # Use Welch's t-test\n",
        "\n",
        "# Step 4: Display results\n",
        "print(f\"T-Test Results for {category_1} vs {category_2}\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between the two categories is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between the two categories is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "XhMuc8lIf6xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*7. Seller State*"
      ],
      "metadata": {
        "id": "82AZy-Y-YRAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate average review score per seller state\n",
        "avg_review_score_per_state = data.groupby('seller_state')['review_score'].mean().sort_values(ascending=False)\n",
        "\n",
        "# Step 2: Select top 5 and bottom 5 states\n",
        "top_5_states = avg_review_score_per_state.head(5)\n",
        "bottom_5_states = avg_review_score_per_state.tail(5)\n",
        "\n",
        "# Step 3: Combine the top 5 and bottom 5 into one DataFrame\n",
        "top_and_bottom_5 = pd.concat([top_5_states, bottom_5_states])\n",
        "\n",
        "# Step 4: Plot the bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    x=top_and_bottom_5.index,\n",
        "    y=top_and_bottom_5.values,\n",
        "    palette='coolwarm'\n",
        ")\n",
        "plt.title('Top 5 and Bottom 5 Seller States by Average Review Score', fontsize=16)\n",
        "plt.xlabel('Seller State', fontsize=12)\n",
        "plt.ylabel('Average Review Score', fontsize=12)\n",
        "plt.xticks(rotation=90, ha='right')  # Rotate state names for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pMD54FiaiM0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Choose two seller states to compare\n",
        "category_1 = 'MG'\n",
        "category_2 = 'RJ'\n",
        "\n",
        "# Step 2: Filter data for the two selected seller states\n",
        "category_1_scores = data[data['seller_state'] == category_1]['review_score']\n",
        "category_2_scores = data[data['seller_state'] == category_2]['review_score']\n",
        "\n",
        "# Step 3: Perform t-test\n",
        "t_stat, p_value = ttest_ind(category_1_scores, category_2_scores, equal_var=False)  # Use Welch's t-test\n",
        "\n",
        "# Step 4: Display results\n",
        "print(f\"T-Test Results for {category_1} vs {category_2}\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between the two seller states is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between the two seller states is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "ArDU5PLnizCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*8. Delivery Time*"
      ],
      "metadata": {
        "id": "QmvcCOowsITZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average delivery time for each review score\n",
        "avg_delivery_time = data.groupby('review_score')['delivery_time'].mean().reset_index()\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=avg_delivery_time, x='review_score', y='delivery_time', palette='Set2')\n",
        "plt.title('Average Delivery Time by Review Score', fontsize=16)\n",
        "plt.xlabel('Review Score', fontsize=12)\n",
        "plt.ylabel('Average Delivery Time (Days)', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vk1bVCIw5GGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the threshold for \"on-time\" vs \"late\"\n",
        "# We'll use the median delivery time as the cutoff\n",
        "median_delivery_time = data['delivery_time'].median()\n",
        "\n",
        "# Step 2: Split the data into two groups based on the delivery time threshold\n",
        "on_time_reviews = data[data['delivery_time'] <= median_delivery_time]['review_score']\n",
        "late_reviews = data[data['delivery_time'] > median_delivery_time]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(on_time_reviews, late_reviews, equal_var=False)\n",
        "\n",
        "# Step 4: Print Results\n",
        "print(\"T-Test: On-time vs Late Deliveries\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between on-time and late deliveries is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between on-time and late deliveries is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "4FvnXnnI5JgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*9. Delivery Delay*"
      ],
      "metadata": {
        "id": "raAAKTint-3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define late deliveries (e.g., deliveries with delay > 0)\n",
        "data['late_delivery'] = data['delivery_delay'] > 0\n",
        "\n",
        "# Calculate the proportion of late deliveries by review score\n",
        "late_delivery_proportion = data.groupby('review_score')['late_delivery'].mean().reset_index()\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=late_delivery_proportion, x='review_score', y='late_delivery', palette='Set2')\n",
        "plt.title('Proportion of Late Deliveries by Review Score', fontsize=16)\n",
        "plt.xlabel('Review Score', fontsize=12)\n",
        "plt.ylabel('Proportion of Late Deliveries', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sR3Ar9rA8Rsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define On-time and Late Deliveries\n",
        "# Late deliveries are where the delivery delay is greater than 0 (i.e., late deliveries)\n",
        "data['late_delivery'] = data['delivery_delay'] > 0\n",
        "\n",
        "# Step 2: Split the data into on-time and late deliveries\n",
        "on_time_reviews = data[data['late_delivery'] == False]['review_score']\n",
        "late_reviews = data[data['late_delivery'] == True]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(on_time_reviews, late_reviews, equal_var=False)\n",
        "\n",
        "# Step 4: Print Results\n",
        "print(\"T-Test: On-time vs Late Deliveries\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between on-time and late deliveries is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between on-time and late deliveries is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "4GJUnZ8t5N_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*10. Freight Price Ratio*"
      ],
      "metadata": {
        "id": "sGNEYuCVuHrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average freight price ratio for each review score\n",
        "avg_freight_price_ratio = data.groupby('review_score')['freight_price_ratio'].mean().reset_index()\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=avg_freight_price_ratio, x='review_score', y='freight_price_ratio', palette='Set2')\n",
        "plt.title('Average Freight Price Ratio by Review Score', fontsize=16)\n",
        "plt.xlabel('Review Score', fontsize=12)\n",
        "plt.ylabel('Average Freight Price Ratio (Freight Value / Price)', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RZQcWWXzrkMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define high and low freight price ratio (e.g., greater than 1 is high)\n",
        "threshold = 1\n",
        "data['high_freight_ratio'] = data['freight_price_ratio'] > threshold\n",
        "\n",
        "# Step 2: Split data into high and low freight price ratio\n",
        "high_freight_reviews = data[data['high_freight_ratio'] == True]['review_score']\n",
        "low_freight_reviews = data[data['high_freight_ratio'] == False]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(high_freight_reviews, low_freight_reviews, equal_var=False)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"T-Test: High vs Low Freight Price Ratio\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between high and low freight price ratio is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between high and low freight price ratio is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "k2X5777u5Wpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*11. Product Name Length*"
      ],
      "metadata": {
        "id": "-Y0Y4_wVY6ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bins for product name length to group similar ranges\n",
        "data['product_name_length_bins'] = pd.cut(data['product_name_lenght'], bins=10)\n",
        "\n",
        "# Box plot of review scores across product name length ranges\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(data=data, x='product_name_length_bins', y='review_score', palette='Set2')\n",
        "plt.title('Review Score Distribution Across Product Name Length Ranges', fontsize=16)\n",
        "plt.xlabel('Product Name Length Range', fontsize=12)\n",
        "plt.ylabel('Review Score', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate length bins for readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zRRThXU9kJp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define a threshold for product name length\n",
        "threshold = 40\n",
        "\n",
        "# Step 2: Split the data into two groups based on the threshold\n",
        "short_names = data[data['product_name_lenght'] <= threshold]['review_score']\n",
        "long_names = data[data['product_name_lenght'] > threshold]['review_score']\n",
        "\n",
        "# Step 3: Perform t-test\n",
        "t_stat, p_value = ttest_ind(short_names, long_names, equal_var=False)  # Use Welch's t-test\n",
        "\n",
        "# Step 4: Display results\n",
        "print(\"T-Test Results for Product Name Length (Short vs. Long):\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between short and long product names is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between short and long product names is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "7RElU43ckpx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*12. Product Weight*"
      ],
      "metadata": {
        "id": "dz0kKP6wY7Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bins for product weight\n",
        "data['product_weight_bins'] = pd.cut(data['product_weight_g'], bins=10, labels=False)  # 10 bins, labeled numerically\n",
        "\n",
        "# Calculate average review scores for each product weight range\n",
        "avg_review_score_by_weight = data.groupby('product_weight_bins')['review_score'].mean().reset_index()\n",
        "\n",
        "# Bar plot of average review score across product weight ranges\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(data=avg_review_score_by_weight, x='product_weight_bins', y='review_score', palette='coolwarm')\n",
        "plt.title('Average Review Score Across Product Weight Ranges', fontsize=16)\n",
        "plt.xlabel('Product Weight Range (g)', fontsize=12)\n",
        "plt.ylabel('Average Review Score', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xqw-hNs8mBYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define a weight threshold\n",
        "threshold = 1000   # 10000 grams (10kg) as the threshold for light vs. heavy products\n",
        "\n",
        "# Step 2: Split the data into two groups based on the threshold\n",
        "light_products = data[data['product_weight_g'] <= threshold]['review_score']\n",
        "heavy_products = data[data['product_weight_g'] > threshold]['review_score']\n",
        "\n",
        "# Step 3: Perform t-test\n",
        "t_stat, p_value = ttest_ind(light_products, heavy_products, equal_var=False)  # Use Welch's t-test\n",
        "\n",
        "# Step 4: Display results\n",
        "print(\"T-Test Results for Product Weight (Light vs. Heavy):\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between light and heavy products is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between light and heavy products is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "xA1bYqW5mjx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*13. Review to Delivery Time*"
      ],
      "metadata": {
        "id": "y7WllHkluCpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average review score for each time range\n",
        "avg_review_score_by_delivery_time = data.groupby('review_to_delivery_time')['review_score'].mean().reset_index()\n",
        "\n",
        "# Line plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.lineplot(data=avg_review_score_by_delivery_time, x='review_to_delivery_time', y='review_score', marker='o', color='green')\n",
        "plt.title('Average Review Score Across Review to Delivery Time Ranges', fontsize=16)\n",
        "plt.xlabel('Review to Delivery Time Range (days)', fontsize=12)\n",
        "plt.ylabel('Average Review Score', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate bins for readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Db-wOEdw5P8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the Groups (On-time vs Late reviews)\n",
        "# On-time reviews: review_to_delivery_time <= 0\n",
        "# Late reviews: review_to_delivery_time > 0\n",
        "data['late_review'] = data['review_to_delivery_time'] > 0\n",
        "\n",
        "# Step 2: Split the data into on-time and late reviews\n",
        "on_time_reviews = data[data['late_review'] == False]['review_score']\n",
        "late_reviews = data[data['late_review'] == True]['review_score']\n",
        "\n",
        "# Step 3: Perform T-Test\n",
        "t_stat, p_value = ttest_ind(on_time_reviews, late_reviews, equal_var=False)\n",
        "\n",
        "# Step 4: Print Results\n",
        "print(\"T-Test: On-time vs Late Reviews\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference in review scores between on-time and late reviews is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in review scores between on-time and late reviews is not statistically significant.\")\n"
      ],
      "metadata": {
        "id": "D1b5RjIV5RuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through the above analysis, the following features have been proven to be significant:\n",
        "1. Customer State\n",
        "2. Payment Type\n",
        "3. Payment Installments\n",
        "4. Freight Value\n",
        "5. Product Category\n",
        "6. Seller State\n",
        "7. Delivery Time\n",
        "8. Delivery Delay\n",
        "9. Freight Price Ratio\n",
        "10. Product Name Length\n",
        "11. Product Weight\n",
        "12. Review to Delivery Time\n",
        "\n",
        "\n",
        "Apart from these, some statistically insignificant features like:\n",
        "13. Price\n",
        "\n",
        "\n",
        "will also be included. While these features may not show strong individual relationships with the target variable, machine learning models, particularly non-linear ones like Random Forests and Gradient Boosting, can uncover complex, non-linear interactions that statistical tests might miss. Some features, despite being statistically insignificant, may still hold business relevance or improve model interpretability. Lastly, including all potentially relevant features helps the model generalize better and remain robust to future data changes.\n",
        "\n",
        "The remaining features were excluded from the analysis because they either showed negligible correlation with the target variable or added redundancy due to high multicollinearity with other included features. Additionally, some features were irrelevant to the problem context or lacked sufficient variance to contribute meaningfully to the predictive model. By excluding these features, we aim to simplify the model, reduce noise, and improve computational efficiency without compromising predictive performance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DIc6b5GCCgyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "XTY1zzXje-XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
        "from xgboost import XGBClassifier as XGB\n",
        "from sklearn.linear_model import LogisticRegression as LogR\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier as DTC\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as CM\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "Lm4AspJO2dXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of features to keep\n",
        "features_to_keep = [\n",
        "    'customer_state',                      # Customer State\n",
        "    'payment_type',                        # Payment Type\n",
        "    'payment_installments',                # Payment Installments\n",
        "    'price',                               # Price\n",
        "    'freight_value',                       # Freight Value\n",
        "    'product_category_name_english',       # Product Category\n",
        "    'seller_state',                        # Seller State\n",
        "    'delivery_time',                       # Delivery Time\n",
        "    'delivery_delay',                      # Delivery Delay\n",
        "    'freight_price_ratio',                 # Freight Price Ratio\n",
        "    'product_name_lenght',                 # Product Name Length\n",
        "    'product_weight_g',                    # Product Weight\n",
        "    'review_to_delivery_time',             # Review from Delivery Time\n",
        "    'review_score'                         # Review Score\n",
        "]\n",
        "\n",
        "# Select the relevant columns\n",
        "data_prepared = data[features_to_keep]\n"
      ],
      "metadata": {
        "id": "ab4nr51IEw0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print info of the filtered data\n",
        "print(data_prepared.info())"
      ],
      "metadata": {
        "id": "Hy3F9uyfU9tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for payment_type, customer_state, product_category_name_english and seller_state columns\n",
        "encoded_data = pd.get_dummies(data_prepared, columns=['payment_type', 'customer_state','product_category_name_english','seller_state'], drop_first=True)\n",
        "\n",
        "# Verifying the result of one-hot encoding\n",
        "print(f\"Columns after one-hot encoding:\\n{encoded_data.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "h7HuY7iaXx7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifying reviews into 2 categories\n",
        "encoded_data['review_classified'] = encoded_data['review_score'].apply(lambda x: 0 if x <= 3 else 1)\n",
        "\n",
        "# Verifying Result\n",
        "print(encoded_data.head())\n",
        "\n",
        "# Dropping original review score column\n",
        "encoded_data = encoded_data.drop(columns=['review_score'])"
      ],
      "metadata": {
        "id": "DBp3oFXBZdN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class balance\n",
        "review_score_counts = encoded_data['review_classified'].value_counts()\n",
        "review_score_proportion = review_score_counts / review_score_counts.sum()\n",
        "print(review_score_proportion)"
      ],
      "metadata": {
        "id": "Q3UEMYN7Itx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "features = encoded_data.drop(columns=['review_classified'])\n",
        "target = encoded_data['review_classified']\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Recreate features DataFrame with scaled data\n",
        "features = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.2, random_state=1984)\n",
        "\n",
        "# Check shapes\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "metadata": {
        "id": "tJttd_ihZ9Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the models\n",
        "DTC_algo = DTC()\n",
        "DTC_model = DTC_algo.fit(X_train, Y_train)\n",
        "\n",
        "svm_algo = SVC()\n",
        "SVM_modedl = svm_algo.fit(X_train, Y_train)\n",
        "\n",
        "LogR_algo = LogR()\n",
        "LogR_model = LogR_algo.fit(X_train, Y_train)\n",
        "\n",
        "RF_algo = RF()\n",
        "RF_model = RF_algo.fit(X_train, Y_train)\n",
        "\n",
        "GBDT_algo = GBDT()\n",
        "GBDT_model = GBDT_algo.fit(X_train, Y_train)\n",
        "\n",
        "XGB_algo = XGB()\n",
        "XGB_model = XGB_algo.fit(X_train, Y_train)\n",
        "\n",
        "models = [DTC_model,SVM_modedl,LogR_model, RF_model, GBDT_model, XGB_model]\n",
        "names = ['Decison Tree','SVM','Logistic Regression', 'Random Forest', 'GBDT', 'XGBDT']\n",
        "\n",
        "for i in range(len(models)):\n",
        "    print(f\"Model: {names[i]}\")\n",
        "\n",
        "    # Predict based on the training data\n",
        "    predict = models[i].predict(X_train)\n",
        "\n",
        "    # Calculate accuracy, precision, recall, and F1-score\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(Y_train, predict, average='macro')\n",
        "    accuracy = accuracy_score(Y_train, predict)\n",
        "    print(f\"Macro Accuracy: {accuracy}\")\n",
        "    print(f\"Macro Precision: {precision}\")\n",
        "    print(f\"Macro Recall: {recall}\")\n",
        "    print(f\"Macro F1-score: {f1_score}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Evaluate the models\n",
        "\n",
        "for i in range(len(models)):\n",
        "    print(f\"Model: {names[i]}\")\n",
        "\n",
        "    # Predict based on the test data\n",
        "    predict = models[i].predict(X_test)\n",
        "\n",
        "    # Calculate accuracy, precision, recall, and F1-score\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(Y_test, predict, average='macro')\n",
        "    accuracy = accuracy_score(Y_test, predict)\n",
        "    print(f\"Macro Accuracy: {accuracy}\")\n",
        "    print(f\"Macro Precision: {precision}\")\n",
        "    print(f\"Macro Recall: {recall}\")\n",
        "    print(f\"Macro F1-score: {f1_score}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(Y_test, predict)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "    plt.title(f\"Confusion Matrix - {names[i]}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "s97KV-nkeivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class imbalance\n",
        "review_score_counts = encoded_data['review_classified'].value_counts()\n",
        "review_score_proportion = review_score_counts / review_score_counts.sum()\n",
        "print(review_score_proportion)"
      ],
      "metadata": {
        "id": "kGRviu_evDG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling for class 0\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=1234,sampling_strategy=0.5)\n",
        "X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "id": "voMrAriNvMkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Create a hyperparameter search function for re-usability\n",
        "def random_search(algo, hyperparameters, X_train, Y_train):\n",
        "  # do the search using 5 folds/chunks\n",
        "  clf = RandomizedSearchCV(algo, hyperparameters, cv=5, random_state=2015,\n",
        "                          scoring='precision_macro', n_iter=20, refit=True)\n",
        "  # pass the data to fit/train\n",
        "  clf.fit(X_train, Y_train)\n",
        "\n",
        "  return clf.best_params_\n",
        "\n",
        "\n",
        "# GBDT\n",
        "GBDT_tuned_parameters = {\n",
        "    'n_estimators': randint(50, 250), # Draw from a uniform distribution between 50 and 250\n",
        "    'learning_rate': uniform(loc=0.01, scale=4.99),  # Draw from a uniform distribution between 0.01 and 5\n",
        "    'criterion': ['friedman_mse', 'squared_error'],\n",
        "    'max_depth': randint(2, 7)  # Draw from a uniform distribution between 2 and 7\n",
        "}\n",
        "\n",
        "GBDT_best_params = random_search(GBDT_algo, GBDT_tuned_parameters, X_train, Y_train)\n",
        "\n",
        "print(\"GBDT Best Parameters:\", GBDT_best_params)\n",
        "\n",
        "# Train the models\n",
        "GBDT_algo = GBDT(**GBDT_best_params)\n",
        "GBDT_model = GBDT_algo.fit(X_train, Y_train)\n",
        "\n",
        "print('Model: GBDT Train：')\n",
        "\n",
        "# predict based on training data\n",
        "predict = GBDT_model.predict(X_train)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(Y_train, predict, average='macro')\n",
        "accuracy = accuracy_score(Y_train, predict)\n",
        "print(f\"Macro Accuracy: {accuracy}\")\n",
        "print(f\"Macro Precision: {precision}\")\n",
        "print(f\"Macro Recall: {recall}\")\n",
        "print(f\"Macro F1-score: {f1_score}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print('Model: GBDT Test：')\n",
        "\n",
        "# predict based on test data\n",
        "predict = GBDT_model.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(Y_test, predict, average='macro')\n",
        "accuracy = accuracy_score(Y_test, predict)\n",
        "print(f\"Macro Accuracy: {accuracy}\")\n",
        "print(f\"Macro Precision: {precision}\")\n",
        "print(f\"Macro Recall: {recall}\")\n",
        "print(f\"Macro F1-score: {f1_score}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(Y_test, predict)\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.title(f\"Confusion Matrix - GBDT\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qYdkeA_0HU1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}